import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')


# Reading .csv file
raw = pd.read_csv('Crop_recommendation.csv')


# Copying the data frame so that original one stay intact.

processed = raw.copy()


processed





# Labels
processed.label.unique()


processed.label.value_counts()
# No data imbalance in Label or target.


# Visualizing label

plt.figure(figsize=(14, 6))

sns.countplot(
    data=processed,
    x='label',
    palette='viridis'
)

plt.title('Crop Label Distribution', fontsize=16, fontweight='bold')
plt.xlabel('Crop Label', fontsize=15, fontweight='bold')
plt.ylabel('Count', fontsize=12, fontweight='bold')
plt.grid(axis='y', linestyle='--', alpha=1, color='black')

plt.xticks(rotation=45, ha='right', fontsize=10, fontweight='bold')
plt.yticks(fontsize=12, fontweight='bold')

plt.tight_layout()
plt.show()


# As the label is a categorical column, so we have to do do label encoding

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

processed['label'] = encoder.fit_transform(processed['label'])


print(f"Unique labels after enoding -> {processed.label.unique()}")


print("No of unique classes -> ", processed.label.nunique())


processed.label.value_counts().sort_index()





label_mapping_df = pd.DataFrame({
    'Number': range(len(encoder.classes_)),
    'Name': encoder.classes_
})

# Save mapping to CSV
label_mapping_df.to_csv('Label_numbers.csv', index=False)

print("✅ Label mapping saved as 'Label_numbers.csv'")


processed





processed.describe()
# As we can see min and max are not 0 and 1 or  , so we can do sacling.
# Also we can do Standard scaling.





features = processed.drop('label', axis=1).select_dtypes(include='number').columns.tolist()
features





plt.figure(figsize=(20,14))

for indx, col in enumerate(features):
    plt.subplot(1, len(features), indx+1)

    sns.boxenplot(y=processed[col], color='red')
    plt.title(f"Boxplot of {col}",fontsize=15, fontweight='bold')

    plt.ylabel(f'{col}', fontsize=15, fontweight='bold')
    plt.tight_layout()

plt.suptitle("Boxplots of Numerical Features (Before Outlier Treatment)", fontsize=18, y=1.02, fontweight='bold')
plt.show()





outlier_counts = {}

for col in features:
    Q1 = processed[col].quantile(0.25)
    Q3 = processed[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = processed[(processed[col] < lower_bound) | (processed[col] > upper_bound)]
    outlier_counts[col] = len(outliers)

# Display outlier counts as a DataFrame
outlier_df = pd.DataFrame.from_dict(outlier_counts, orient='index', columns=['Outlier_Count'])
outlier_df.sort_values(by='Outlier_Count', ascending=False, inplace=True)
print(outlier_df)





# List of columns for outlier treatment
outlier_cols = ['K', 'P', 'rainfall']

# Function to apply IQR-based capping
def cap_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Capping values outside the bounds
    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)

    # Any value below the lower bound is replaced with the lower bound.

    # Any value above the upper bound is replaced with the upper bound.
    
    # All other values remain the same.

    print(f"✅ Treated outliers in '{column}' using IQR capping.")

# Apply to the 'processed' dataframe
for col in outlier_cols:
    cap_outliers_iqr(processed, col)





plt.figure(figsize=(20,14))

for indx, col in enumerate(features):
    plt.subplot(1, len(features), indx+1)

    sns.boxenplot(y=processed[col], color='orange')
    plt.title(f"Boxplot of {col}",fontsize=15, fontweight='bold')

    plt.ylabel(f'{col}', fontsize=15, fontweight='bold')
    plt.tight_layout()

plt.suptitle("Boxplots of Numerical Features (After Outlier Treatment)", fontsize=18, y=1.02, fontweight='bold')
plt.show()





processed.isna().sum()
# No Null value in the dataset


processed.describe()





plt.figure(figsize=(18, 12))
for i, col in enumerate(features, 1):
    plt.subplot(3, 3, i)
    sns.histplot(processed[col], kde=True, bins=20, color='blue')
    plt.title(f"Distribution of {col}", fontweight='bold')
    plt.xlabel(col, fontsize=10, fontweight='bold')
    plt.ylabel("Frequency", fontsize=12, fontweight='bold')
    plt.grid(True, linestyle='--', alpha=0.4, color='black')

plt.suptitle("Distribution of Numerical Features (Before Scaling)\n", fontsize=18, fontweight='bold')
plt.tight_layout()
plt.show()





from sklearn.preprocessing import StandardScaler

# Separate label
label_col = processed['label']
features_only = processed.drop('label', axis=1)

# Apply StandardScaler only on numerical features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features_only)

# Convert back to DataFrame
scaled_df = pd.DataFrame(scaled_features, columns=features_only.columns)

# Reattach the label column
processed = pd.concat([scaled_df, label_col.reset_index(drop=True)], axis=1)


processed





plt.figure(figsize=(18, 12))

for i, col in enumerate(features, 1):
    plt.subplot(3, 3, i)
    sns.histplot(processed[col], kde=True, bins=20, color='mediumseagreen')
    plt.axvline(0, color='red', linestyle='--', label='Mean = 0')
    plt.title(f"Distribution of {col}", fontweight='bold')
    plt.xlabel("")
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.3)
    
plt.suptitle("Distribution of Numerical Features (After Scaling)\n", fontsize=18, fontweight='bold')
plt.tight_layout()
plt.show()


processed.describe()
# Standard scaler done success fully





processed.to_csv('Cleaned_dataset.csv', index=False)
print("Saved as Claened_dataset.csv")


processed.label.value_counts().sort_index()



